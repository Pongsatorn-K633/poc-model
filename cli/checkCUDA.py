import torch

def check_cuda():
    print("üîç Checking CUDA availability...\n")
    
    if torch.cuda.is_available():
        print("‚úÖ CUDA is available!")
        print(f"üñ•Ô∏è  GPU Device Name : {torch.cuda.get_device_name(0)}")
        print(f"üî¢ Number of Devices: {torch.cuda.device_count()}")
        print(f"üß© CUDA Version     : {torch.version.cuda}\n")
    else:
        print("‚ùå CUDA is NOT available.")
        print("‚ö†Ô∏è  Possible reasons:")
        print("- CUDA-capable GPU not found or drivers not installed.")
        print("- Installed PyTorch version is CPU-only.")
        print("- CUDA Toolkit or PyTorch CUDA not installed in environment.\n")
        
# def check_model():
#     import os
#     print(os.path.exists("yolo11m.pt"))  # should return True


if __name__ == "__main__":
    check_cuda()
    # check_model()

